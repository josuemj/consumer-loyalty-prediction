{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75fea373",
   "metadata": {},
   "source": [
    "# Proceo de Limpieza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf70d0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a100c81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = pd.read_csv('../data/test_format2.csv')\n",
    "data_train = pd.read_csv('../data/train_format2.csv')\n",
    "\n",
    "# La limpieza de datos se realiza en ambos datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c66eb92",
   "metadata": {},
   "source": [
    "# Validaciones rapidas para entender como estan los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62485b5",
   "metadata": {},
   "source": [
    "## Visión rápida: tamaños, tipos y nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3587e4a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TRAIN ===\n",
      "shape: (7030723, 6)\n",
      "user_id           int64\n",
      "age_range       float64\n",
      "gender          float64\n",
      "merchant_id       int64\n",
      "label             int64\n",
      "activity_log     object\n",
      "dtype: object\n",
      "\n",
      "=== TEST ===\n",
      "shape: (7027943, 6)\n",
      "user_id           int64\n",
      "age_range       float64\n",
      "gender          float64\n",
      "merchant_id       int64\n",
      "label           float64\n",
      "activity_log     object\n",
      "dtype: object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tamaños y tipos\n",
    "for name, df in {\"train\": data_train, \"test\": data_test}.items():\n",
    "    print(f\"=== {name.upper()} ===\")\n",
    "    print(\"shape:\", df.shape)\n",
    "    print(df.dtypes)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f4eef32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== NULLS TRAIN ===\n",
      "gender          61712\n",
      "age_range       19380\n",
      "activity_log     2975\n",
      "user_id             0\n",
      "merchant_id         0\n",
      "label               0\n",
      "dtype: int64\n",
      "\n",
      "=== NULLS TEST ===\n",
      "label           261477\n",
      "gender           63250\n",
      "age_range        19420\n",
      "activity_log      3006\n",
      "user_id              0\n",
      "merchant_id          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Conteo de nulos por columna\n",
    "print(\"=== NULLS TRAIN ===\")\n",
    "print(data_train.isna().sum().sort_values(ascending=False))\n",
    "print(\"\\n=== NULLS TEST ===\")\n",
    "print(data_test.isna().sum().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978af6c5",
   "metadata": {},
   "source": [
    "## Variables clave: distribución de label (train), age_range, gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0aadf79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== LABEL value_counts (TRAIN) ===\n",
      "label\n",
      "-1    6769859\n",
      " 0     244912\n",
      " 1      15952\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== age_range (TRAIN) ===\n",
      "age_range\n",
      "0.0    1351842\n",
      "1.0        286\n",
      "2.0     731938\n",
      "3.0    1913722\n",
      "4.0    1459923\n",
      "5.0     752927\n",
      "6.0     655922\n",
      "7.0     124493\n",
      "8.0      20290\n",
      "NaN      19380\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== age_range (TEST) ===\n",
      "age_range\n",
      "0.0    1345565\n",
      "1.0        260\n",
      "2.0     733323\n",
      "3.0    1916611\n",
      "4.0    1460542\n",
      "5.0     752608\n",
      "6.0     650358\n",
      "7.0     128644\n",
      "8.0      20612\n",
      "NaN      19420\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== gender (TRAIN) ===\n",
      "gender\n",
      "0.0    5101730\n",
      "1.0    1618110\n",
      "2.0     249171\n",
      "NaN      61712\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== gender (TEST) ===\n",
      "gender\n",
      "0.0    5062667\n",
      "1.0    1643382\n",
      "2.0     258644\n",
      "NaN      63250\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Distribución de label en TRAIN (incluye -1 si hay)\n",
    "print(\"=== LABEL value_counts (TRAIN) ===\")\n",
    "print(data_train['label'].value_counts(dropna=False))\n",
    "\n",
    "# Edad y género (TRAIN y TEST)\n",
    "def vc_with_na(s):\n",
    "    return s.value_counts(dropna=False).sort_index()\n",
    "\n",
    "print(\"\\n=== age_range (TRAIN) ===\")\n",
    "print(vc_with_na(data_train['age_range']))\n",
    "\n",
    "print(\"\\n=== age_range (TEST) ===\")\n",
    "print(vc_with_na(data_test['age_range']))\n",
    "\n",
    "print(\"\\n=== gender (TRAIN) ===\")\n",
    "print(vc_with_na(data_train['gender']))\n",
    "\n",
    "print(\"\\n=== gender (TEST) ===\")\n",
    "print(vc_with_na(data_test['gender']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d4e392",
   "metadata": {},
   "source": [
    "## activity_log: calidad básica (vacíos, longitud, ejemplos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f12e030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TRAIN activity_len ===\n",
      "count    7.030723e+06\n",
      "mean     3.894925e+00\n",
      "std      1.214883e+01\n",
      "min      0.000000e+00\n",
      "25%      1.000000e+00\n",
      "50%      1.000000e+00\n",
      "75%      3.000000e+00\n",
      "max      6.963000e+03\n",
      "Name: activity_len, dtype: float64\n",
      "Ceros (sin interacciones): 2975\n",
      "\n",
      "=== TEST activity_len ===\n",
      "count    7.027943e+06\n",
      "mean     3.905862e+00\n",
      "std      1.275945e+01\n",
      "min      0.000000e+00\n",
      "25%      1.000000e+00\n",
      "50%      1.000000e+00\n",
      "75%      3.000000e+00\n",
      "max      7.688000e+03\n",
      "Name: activity_len, dtype: float64\n",
      "Ceros (sin interacciones): 3006\n",
      "\n",
      "=== EJEMPLOS activity_log (TRAIN) ===\n",
      "['408895:1505:7370:1107:0', '17235:1604:4396:0818:0#954723:1604:4396:0818:0#275437:1604:4396:0818:0#548906:1577:4396:1031:0#368206:662:4396:0818:0#480007:1604:4396:0818:0#954723:1604:4396:0818:0#236488:1505:4396:1024:0', '231901:662:2758:0818:0#231901:662:2758:0818:0#108465:662:2758:0820:0#231901:662:2758:0820:0#231901:662:2758:0820:0#840446:1142:2758:0820:0#231901:662:2758:0819:0']\n"
     ]
    }
   ],
   "source": [
    "# Longitud de log por registro (nº de interacciones por fila)\n",
    "def count_interactions(x):\n",
    "    if pd.isna(x) or x == '':\n",
    "        return 0\n",
    "    return len(str(x).split('#'))\n",
    "\n",
    "for name, df in {\"train\": data_train, \"test\": data_test}.items():\n",
    "    df['activity_len'] = df['activity_log'].apply(count_interactions)\n",
    "    print(f\"=== {name.upper()} activity_len ===\")\n",
    "    print(df['activity_len'].describe())\n",
    "    print(\"Ceros (sin interacciones):\", (df['activity_len'] == 0).sum())\n",
    "    print()\n",
    "\n",
    "# Muestra de 3 filas con logs no vacíos\n",
    "print(\"=== EJEMPLOS activity_log (TRAIN) ===\")\n",
    "print(data_train.loc[data_train['activity_len']>0, 'activity_log'].head(3).to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13187f98",
   "metadata": {},
   "source": [
    "## Parseo mínimo del activity_log: validar formato y action_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dfc180ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ACTION TYPES (TRAIN, muestra 2000 filas) ===\n",
      "malformados (TRAIN muestra): 0\n",
      "action_types (TRAIN muestra): [('0', 6551), ('3', 503), ('2', 463)]\n",
      "\n",
      "=== ACTION TYPES (TEST, muestra 2000 filas) ===\n",
      "malformados (TEST muestra): 0\n",
      "action_types (TEST muestra): [('0', 6860), ('3', 601), ('2', 417)]\n"
     ]
    }
   ],
   "source": [
    "def parse_records(log):\n",
    "    \"\"\"\n",
    "    Devuelve lista de tuplas (item_id, category_id, brand_id, time_stamp, action_type)\n",
    "    o [] si vacío/malformado.\n",
    "    \"\"\"\n",
    "    if pd.isna(log) or log == '':\n",
    "        return []\n",
    "    recs = []\n",
    "    for rec in str(log).split('#'):\n",
    "        parts = rec.split(':')\n",
    "        if len(parts) == 5:\n",
    "            recs.append(tuple(parts))\n",
    "        else:\n",
    "            recs.append(None)\n",
    "    return recs\n",
    "\n",
    "def sample_action_types(df, n_rows=2000):\n",
    "    atypes = Counter()\n",
    "    malformed = 0\n",
    "    for log in df['activity_log'].head(n_rows):\n",
    "        recs = parse_records(log)\n",
    "        for r in recs:\n",
    "            if r is None:\n",
    "                malformed += 1\n",
    "            else:\n",
    "                atypes.update([r[4]])\n",
    "    return atypes, malformed\n",
    "\n",
    "print(\"=== ACTION TYPES (TRAIN, muestra 2000 filas) ===\")\n",
    "atypes_train, malformed_train = sample_action_types(data_train, 2000)\n",
    "print(\"malformados (TRAIN muestra):\", malformed_train)\n",
    "print(\"action_types (TRAIN muestra):\", atypes_train.most_common(20))\n",
    "\n",
    "print(\"\\n=== ACTION TYPES (TEST, muestra 2000 filas) ===\")\n",
    "atypes_test, malformed_test = sample_action_types(data_test, 2000)\n",
    "print(\"malformados (TEST muestra):\", malformed_test)\n",
    "print(\"action_types (TEST muestra):\", atypes_test.most_common(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7caa69",
   "metadata": {},
   "source": [
    "## Validación de time_stamp: rango temporal, parseo y errores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f3c1baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TIMESTAMPS (TRAIN muestra 2000 filas) ===\n",
      "parseables: 0 no parseables: 7517\n",
      "\n",
      "=== TIMESTAMPS (TEST muestra 2000 filas) ===\n",
      "parseables: 0 no parseables: 7878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiag\\AppData\\Local\\Temp\\ipykernel_30120\\2817643149.py:10: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  ts = pd.to_datetime(pd.Series(tvals), errors='coerce', infer_datetime_format=True)\n",
      "C:\\Users\\thiag\\AppData\\Local\\Temp\\ipykernel_30120\\2817643149.py:10: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  ts = pd.to_datetime(pd.Series(tvals), errors='coerce', infer_datetime_format=True)\n",
      "C:\\Users\\thiag\\AppData\\Local\\Temp\\ipykernel_30120\\2817643149.py:10: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  ts = pd.to_datetime(pd.Series(tvals), errors='coerce', infer_datetime_format=True)\n",
      "C:\\Users\\thiag\\AppData\\Local\\Temp\\ipykernel_30120\\2817643149.py:10: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  ts = pd.to_datetime(pd.Series(tvals), errors='coerce', infer_datetime_format=True)\n"
     ]
    }
   ],
   "source": [
    "def extract_timestamps(df, n_rows=2000):\n",
    "    tvals = []\n",
    "    bad = 0\n",
    "    for log in df['activity_log'].head(n_rows):\n",
    "        recs = parse_records(log)\n",
    "        for r in recs:\n",
    "            if r is None:\n",
    "                continue\n",
    "            tvals.append(r[3])\n",
    "    ts = pd.to_datetime(pd.Series(tvals), errors='coerce', infer_datetime_format=True)\n",
    "    bad = ts.isna().sum()\n",
    "    return ts, bad\n",
    "\n",
    "print(\"=== TIMESTAMPS (TRAIN muestra 2000 filas) ===\")\n",
    "ts_train, bad_train = extract_timestamps(data_train, 2000)\n",
    "print(\"parseables:\", ts_train.notna().sum(), \"no parseables:\", bad_train)\n",
    "if ts_train.notna().any():\n",
    "    print(\"min:\", ts_train.min(), \"max:\", ts_train.max())\n",
    "\n",
    "print(\"\\n=== TIMESTAMPS (TEST muestra 2000 filas) ===\")\n",
    "ts_test, bad_test = extract_timestamps(data_test, 2000)\n",
    "print(\"parseables:\", ts_test.notna().sum(), \"no parseables:\", bad_test)\n",
    "if ts_test.notna().any():\n",
    "    print(\"min:\", ts_test.min(), \"max:\", ts_test.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ccc0dc",
   "metadata": {},
   "source": [
    "## Duplicados potenciales (por par usuario–comerciante)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9683981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Duplicados exactos ===\n",
      "TRAIN: 0\n",
      "TEST: 0\n",
      "\n",
      "=== Duplicados por (user_id, merchant_id) ===\n",
      "TRAIN: 0\n",
      "TEST: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Duplicados exactos ===\")\n",
    "print(\"TRAIN:\", data_train.duplicated().sum())\n",
    "print(\"TEST:\", data_test.duplicated().sum())\n",
    "\n",
    "def dup_pairs(df):\n",
    "    if all(c in df.columns for c in ['user_id', 'merchant_id']):\n",
    "        return df.duplicated(subset=['user_id','merchant_id']).sum()\n",
    "    return None\n",
    "\n",
    "print(\"\\n=== Duplicados por (user_id, merchant_id) ===\")\n",
    "print(\"TRAIN:\", dup_pairs(data_train))\n",
    "print(\"TEST:\", dup_pairs(data_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
