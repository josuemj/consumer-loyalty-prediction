{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4991e165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-Archivos cargados-\n",
      "Train shape: (7030723, 16)\n",
      "Test  shape: (7027943, 16)\n",
      "\n",
      "--- Primeras 5 filas de train ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>age_range</th>\n",
       "      <th>gender</th>\n",
       "      <th>merchant_id</th>\n",
       "      <th>label</th>\n",
       "      <th>activity_len</th>\n",
       "      <th>actions_0</th>\n",
       "      <th>actions_2</th>\n",
       "      <th>actions_3</th>\n",
       "      <th>unique_items</th>\n",
       "      <th>unique_categories</th>\n",
       "      <th>unique_brands</th>\n",
       "      <th>date_min</th>\n",
       "      <th>date_max</th>\n",
       "      <th>day_span</th>\n",
       "      <th>has_1111</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34176</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>944</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-11-07</td>\n",
       "      <td>2014-11-07</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34176</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>412</td>\n",
       "      <td>-1</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-08-18</td>\n",
       "      <td>2014-10-31</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34176</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1945</td>\n",
       "      <td>-1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-08-18</td>\n",
       "      <td>2014-08-20</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34176</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4752</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-10-27</td>\n",
       "      <td>2014-10-27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34176</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>643</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-10-24</td>\n",
       "      <td>2014-10-24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  age_range  gender  merchant_id  label  activity_len  actions_0  \\\n",
       "0    34176          6       0          944     -1             1          1   \n",
       "1    34176          6       0          412     -1             8          8   \n",
       "2    34176          6       0         1945     -1             7          7   \n",
       "3    34176          6       0         4752     -1             1          1   \n",
       "4    34176          6       0          643     -1             1          0   \n",
       "\n",
       "   actions_2  actions_3  unique_items  unique_categories  unique_brands  \\\n",
       "0          0          0             1                  1              1   \n",
       "1          0          0             7                  4              1   \n",
       "2          0          0             3                  2              1   \n",
       "3          0          0             1                  1              1   \n",
       "4          0          1             1                  1              1   \n",
       "\n",
       "     date_min    date_max  day_span  has_1111  \n",
       "0  2014-11-07  2014-11-07         0         0  \n",
       "1  2014-08-18  2014-10-31        74         0  \n",
       "2  2014-08-18  2014-08-20         2         0  \n",
       "3  2014-10-27  2014-10-27         0         0  \n",
       "4  2014-10-24  2014-10-24         0         0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Tipos de columnas (train) ---\n",
      "int64     14\n",
      "object     2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- Distribución 'label' (train) ---\n",
      "         count      pct\n",
      "label                  \n",
      "-1     6769859  96.2897\n",
      " 0      244912   3.4835\n",
      " 1       15952   0.2269\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "random.seed(RANDOM_STATE)\n",
    "\n",
    "\n",
    "TRAIN_PATH = '../data/train_clean.csv'\n",
    "TEST_PATH = '../data/test_clean.csv'\n",
    "\n",
    "# Cargar datasets\n",
    "train = pd.read_csv(TRAIN_PATH)\n",
    "test = pd.read_csv(TEST_PATH)\n",
    "\n",
    "# Comprobaciones \n",
    "print(\"-Archivos cargados-\")\n",
    "print(f\"Train shape: {train.shape}\")\n",
    "print(f\"Test  shape: {test.shape}\")\n",
    "\n",
    "print(\"\\n--- Primeras 5 filas de train ---\")\n",
    "display(train.head())\n",
    "\n",
    "print(\"\\n--- Tipos de columnas (train) ---\")\n",
    "print(train.dtypes.value_counts())\n",
    "\n",
    "# Distribucion de la variable objetivo en train\n",
    "if 'label' in train.columns:\n",
    "    vc = train['label'].value_counts(dropna=False).sort_index()\n",
    "    pct = train['label'].value_counts(normalize=True, dropna=False).sort_index() * 100\n",
    "    dist_df = pd.DataFrame({'count': vc, 'pct': pct.round(4)})\n",
    "    print(\"\\n--- Distribución 'label' (train) ---\")\n",
    "    print(dist_df)\n",
    "else:\n",
    "    print(\"La columna 'label' NO se encontró en train.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701f078e",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b29406a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.62887\teval-auc:0.61302\n",
      "[10]\ttrain-auc:0.64052\teval-auc:0.62505\n",
      "[20]\ttrain-auc:0.64482\teval-auc:0.62693\n",
      "[30]\ttrain-auc:0.64959\teval-auc:0.62843\n",
      "[40]\ttrain-auc:0.65441\teval-auc:0.63060\n",
      "[50]\ttrain-auc:0.65942\teval-auc:0.63220\n",
      "[60]\ttrain-auc:0.66324\teval-auc:0.63318\n",
      "[70]\ttrain-auc:0.66870\teval-auc:0.63517\n",
      "[80]\ttrain-auc:0.67376\teval-auc:0.63780\n",
      "[90]\ttrain-auc:0.67773\teval-auc:0.63952\n",
      "[100]\ttrain-auc:0.68035\teval-auc:0.64001\n",
      "[110]\ttrain-auc:0.68331\teval-auc:0.64067\n",
      "[120]\ttrain-auc:0.68562\teval-auc:0.64093\n",
      "[130]\ttrain-auc:0.68866\teval-auc:0.64181\n",
      "[140]\ttrain-auc:0.69117\teval-auc:0.64157\n",
      "[150]\ttrain-auc:0.69443\teval-auc:0.64231\n",
      "[160]\ttrain-auc:0.69689\teval-auc:0.64290\n",
      "[170]\ttrain-auc:0.70028\teval-auc:0.64351\n",
      "[180]\ttrain-auc:0.70285\teval-auc:0.64372\n",
      "[190]\ttrain-auc:0.70442\teval-auc:0.64355\n",
      "[200]\ttrain-auc:0.70611\teval-auc:0.64305\n",
      "[210]\ttrain-auc:0.70904\teval-auc:0.64291\n",
      "[220]\ttrain-auc:0.71125\teval-auc:0.64261\n",
      "[225]\ttrain-auc:0.71203\teval-auc:0.64252\n",
      "\n",
      "--- Métricas en validacion ---\n",
      "AUC (val): 0.6425641305917855\n",
      "\n",
      "Classification report (val):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9560    0.7190    0.8208     48983\n",
      "           1     0.1023    0.4915    0.1693      3190\n",
      "\n",
      "    accuracy                         0.7051     52173\n",
      "   macro avg     0.5291    0.6053    0.4950     52173\n",
      "weighted avg     0.9038    0.7051    0.7809     52173\n",
      "\n",
      "\n",
      "Confusion matrix (val):\n",
      "[[35221 13762]\n",
      " [ 1622  1568]]\n",
      "\n",
      "Top 20 features (gain):\n",
      "unique_items         -> gain: 111.206421\n",
      "actions_2            -> gain: 92.323616\n",
      "unique_categories    -> gain: 85.459549\n",
      "merchant_id          -> gain: 47.761753\n",
      "day_span             -> gain: 40.142216\n",
      "gender               -> gain: 33.147820\n",
      "unique_brands        -> gain: 31.918791\n",
      "age_range            -> gain: 30.826199\n",
      "actions_0            -> gain: 30.075500\n",
      "activity_len         -> gain: 29.417440\n",
      "actions_3            -> gain: 24.154499\n",
      "has_1111             -> gain: 9.871352\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "# Convertir a DMatrix (estructura de datos interna optimizada de XGBoost para almacenar features y etiquetas.)\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dval   = xgb.DMatrix(X_val,   label=y_val)\n",
    "\n",
    "# Parametros\n",
    "params = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'auc',\n",
    "    'eta': 0.05,            # learning_rate\n",
    "    'max_depth': 6,\n",
    "    'scale_pos_weight': scale_pos_weight,\n",
    "    'verbosity': 1,\n",
    "    'tree_method': 'hist'   # más eficiente; cambia a 'auto' si prefieres\n",
    "}\n",
    "\n",
    "watchlist = [(dtrain, 'train'), (dval, 'eval')]\n",
    "\n",
    "# Entrenar con early stopping (num_boost_round = n_estimators original)\n",
    "bst = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=1000,\n",
    "    evals=watchlist,\n",
    "    early_stopping_rounds=50,\n",
    "    verbose_eval=10\n",
    ")\n",
    "\n",
    "# Predicciones de probabilidad en validacion\n",
    "y_val_proba = bst.predict(dval)\n",
    "y_val_pred = (y_val_proba >= 0.5).astype(int)\n",
    "\n",
    "# Metricas\n",
    "print(\"\\n--- Métricas en validacion ---\")\n",
    "print(\"AUC (val):\", roc_auc_score(y_val, y_val_proba))\n",
    "print(\"\\nClassification report (val):\")\n",
    "print(classification_report(y_val, y_val_pred, digits=4))\n",
    "print(\"\\nConfusion matrix (val):\")\n",
    "print(confusion_matrix(y_val, y_val_pred))\n",
    "\n",
    "\n",
    "fi = bst.get_score(importance_type='gain')\n",
    "fi_sorted = sorted(fi.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"\\nTop 20 features (gain):\")\n",
    "for f, v in fi_sorted[:20]:\n",
    "    print(f\"{f:20s} -> gain: {v:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f56305ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Precision (PR-AUC): 0.118822\n",
      "Mejor threshold por F1: 0.5827  -> F1: 0.1832\n",
      "Precision@best: 0.1319, Recall@best: 0.2997\n",
      "\n",
      "Classification report (con threshold optimo):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9503    0.8715    0.9092     48983\n",
      "           1     0.1319    0.2997    0.1832      3190\n",
      "\n",
      "    accuracy                         0.8366     52173\n",
      "   macro avg     0.5411    0.5856    0.5462     52173\n",
      "weighted avg     0.9002    0.8366    0.8648     52173\n",
      "\n",
      "\n",
      "Confusion matrix (con threshold optimo):\n",
      "[[42690  6293]\n",
      " [ 2234   956]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve, average_precision_score, f1_score, classification_report, confusion_matrix\n",
    "\n",
    "# 1) PR-AUC (average precision)\n",
    "ap = average_precision_score(y_val, y_val_proba)\n",
    "print(\"Average Precision (PR-AUC):\", round(ap, 6))\n",
    "\n",
    "# 2) Encontrar umbral que maximice F1 en validacion\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_val, y_val_proba)\n",
    "f1_scores = 2 * (precisions[:-1] * recalls[:-1]) / (precisions[:-1] + recalls[:-1] + 1e-12)\n",
    "best_idx = f1_scores.argmax()\n",
    "best_threshold = thresholds[best_idx]\n",
    "best_f1 = f1_scores[best_idx]\n",
    "\n",
    "print(f\"Mejor threshold por F1: {best_threshold:.4f}  -> F1: {best_f1:.4f}\")\n",
    "print(f\"Precision@best: {precisions[:-1][best_idx]:.4f}, Recall@best: {recalls[:-1][best_idx]:.4f}\")\n",
    "\n",
    "# 3) Evaluar con ese umbral\n",
    "y_val_pred_best = (y_val_proba >= best_threshold).astype(int)\n",
    "print(\"\\nClassification report (con threshold optimo):\")\n",
    "print(classification_report(y_val, y_val_pred_best, digits=4))\n",
    "print(\"\\nConfusion matrix (con threshold optimo):\")\n",
    "print(confusion_matrix(y_val, y_val_pred_best))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f761a5d9",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7899c1b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes -> X_train_lgb: (208691, 12) X_val_lgb: (52173, 12)\n",
      "scale_pos_weight (LGB): 15.352530951261558\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[10]\ttrain's average_precision: 0.117801\tvalid's average_precision: 0.11549\n",
      "[20]\ttrain's average_precision: 0.120762\tvalid's average_precision: 0.117246\n",
      "[30]\ttrain's average_precision: 0.122879\tvalid's average_precision: 0.117603\n",
      "[40]\ttrain's average_precision: 0.125651\tvalid's average_precision: 0.118473\n",
      "[50]\ttrain's average_precision: 0.128153\tvalid's average_precision: 0.119987\n",
      "[60]\ttrain's average_precision: 0.131758\tvalid's average_precision: 0.119949\n",
      "[70]\ttrain's average_precision: 0.134135\tvalid's average_precision: 0.119607\n",
      "[80]\ttrain's average_precision: 0.138021\tvalid's average_precision: 0.121288\n",
      "[90]\ttrain's average_precision: 0.141099\tvalid's average_precision: 0.122117\n",
      "[100]\ttrain's average_precision: 0.144531\tvalid's average_precision: 0.122797\n",
      "[110]\ttrain's average_precision: 0.14735\tvalid's average_precision: 0.123027\n",
      "[120]\ttrain's average_precision: 0.149918\tvalid's average_precision: 0.122921\n",
      "[130]\ttrain's average_precision: 0.152547\tvalid's average_precision: 0.122913\n",
      "[140]\ttrain's average_precision: 0.154595\tvalid's average_precision: 0.122714\n",
      "[150]\ttrain's average_precision: 0.157009\tvalid's average_precision: 0.122605\n",
      "[160]\ttrain's average_precision: 0.159571\tvalid's average_precision: 0.122472\n",
      "Early stopping, best iteration is:\n",
      "[113]\ttrain's average_precision: 0.147971\tvalid's average_precision: 0.123226\n",
      "\n",
      "LGB PR-AUC (Average Precision): 0.123226\n",
      "Mejor threshold LGB por F1: 0.6053 -> F1: 0.1875\n",
      "\n",
      "Classification report (LGB, threshold optimo):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9502    0.8826    0.9152     48983\n",
      "           1     0.1386    0.2900    0.1875      3190\n",
      "\n",
      "    accuracy                         0.8464     52173\n",
      "   macro avg     0.5444    0.5863    0.5513     52173\n",
      "weighted avg     0.9006    0.8464    0.8707     52173\n",
      "\n",
      "\n",
      "Confusion matrix (LGB, threshold optimo):\n",
      "[[43233  5750]\n",
      " [ 2265   925]]\n",
      "\n",
      "Top 20 features (gain) LGB:\n",
      "merchant_freq        -> gain: 116165.279728\n",
      "unique_items         -> gain: 95033.639186\n",
      "actions_2            -> gain: 42808.822344\n",
      "day_span             -> gain: 38091.357589\n",
      "unique_categories    -> gain: 36050.078897\n",
      "actions_0            -> gain: 17995.844117\n",
      "age_range            -> gain: 13992.625535\n",
      "gender               -> gain: 8517.452394\n",
      "activity_len         -> gain: 7094.600403\n",
      "actions_3            -> gain: 5781.873428\n",
      "unique_brands        -> gain: 5253.487522\n",
      "has_1111             -> gain: 0.000000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "\n",
    "df_model = train[train['label'].isin([0,1])].copy()  \n",
    "\n",
    "\n",
    "merchant_counts = df_model['merchant_id'].value_counts()\n",
    "df_model['merchant_freq'] = df_model['merchant_id'].map(merchant_counts)\n",
    "\n",
    "\n",
    "features_lgb = [\n",
    "    'activity_len','actions_0','actions_2','actions_3',\n",
    "    'unique_items','unique_categories','unique_brands',\n",
    "    'day_span','has_1111','age_range','gender','merchant_freq'\n",
    "]\n",
    "\n",
    "X = df_model[features_lgb]\n",
    "y = df_model['label'].astype(int)\n",
    "\n",
    "\n",
    "X_train_lgb, X_val_lgb, y_train_lgb, y_val_lgb = train_test_split(\n",
    "    X, y, test_size=0.20, stratify=y, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "\n",
    "scale_pos_weight_lgb = (y_train_lgb==0).sum() / (y_train_lgb==1).sum()\n",
    "print(\"Shapes -> X_train_lgb:\", X_train_lgb.shape, \"X_val_lgb:\", X_val_lgb.shape)\n",
    "print(\"scale_pos_weight (LGB):\", scale_pos_weight_lgb)\n",
    "\n",
    "# ---------- Dataset LightGBM ----------\n",
    "lgb_train = lgb.Dataset(X_train_lgb, label=y_train_lgb)\n",
    "lgb_val   = lgb.Dataset(X_val_lgb, label=y_val_lgb, reference=lgb_train)\n",
    "\n",
    "# ---------- Parametros  ----------\n",
    "lgb_params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'average_precision',\n",
    "    'learning_rate': 0.05,\n",
    "    'num_leaves': 31,\n",
    "    'max_depth': 6,\n",
    "    'verbosity': -1,\n",
    "    'is_unbalance': False,          \n",
    "    'scale_pos_weight': scale_pos_weight_lgb\n",
    "}\n",
    "\n",
    "\n",
    "gbm = lgb.train(\n",
    "    lgb_params,\n",
    "    lgb_train,\n",
    "    num_boost_round=1000,\n",
    "    valid_sets=[lgb_train, lgb_val],\n",
    "    valid_names=['train','valid'],\n",
    "    callbacks=[\n",
    "        lgb.early_stopping(stopping_rounds=50),\n",
    "        lgb.log_evaluation(period=10)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Predicciones y evaluacion \n",
    "y_val_proba_lgb = gbm.predict(X_val_lgb)\n",
    "from sklearn.metrics import average_precision_score, classification_report, confusion_matrix\n",
    "ap_lgb = average_precision_score(y_val_lgb, y_val_proba_lgb)\n",
    "print(\"\\nLGB PR-AUC (Average Precision):\", round(ap_lgb, 6))\n",
    "\n",
    "# Buscar threshold que maximice F1\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_val_lgb, y_val_proba_lgb)\n",
    "f1_scores = 2 * (precisions[:-1] * recalls[:-1]) / (precisions[:-1] + recalls[:-1] + 1e-12)\n",
    "best_idx = f1_scores.argmax()\n",
    "best_threshold_lgb = thresholds[best_idx]\n",
    "print(f\"Mejor threshold LGB por F1: {best_threshold_lgb:.4f} -> F1: {f1_scores[best_idx]:.4f}\")\n",
    "y_val_pred_lgb = (y_val_proba_lgb >= best_threshold_lgb).astype(int)\n",
    "\n",
    "print(\"\\nClassification report (LGB, threshold optimo):\")\n",
    "print(classification_report(y_val_lgb, y_val_pred_lgb, digits=4))\n",
    "print(\"\\nConfusion matrix (LGB, threshold optimo):\")\n",
    "print(confusion_matrix(y_val_lgb, y_val_pred_lgb))\n",
    "\n",
    "# Top features (gain/importance)\n",
    "imp = gbm.feature_importance(importance_type='gain')\n",
    "names = gbm.feature_name()\n",
    "feat_imp = sorted(zip(names, imp), key=lambda x: x[1], reverse=True)\n",
    "print(\"\\nTop 20 features (gain) LGB:\")\n",
    "for n, v in feat_imp[:20]:\n",
    "    print(f\"{n:20s} -> gain: {v:.6f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
